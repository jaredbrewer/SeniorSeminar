if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh(
"trinker/qdapDictionaries",
"trinker/qdapRegex",
"trinker/qdapTools",
"trinker/qdap"
)
library(qdap)
library(data.table)
library(wordcloud)
donald <- read.csv("./DonaldDebate1.csv", header = T)
attach(donald)
wordcloud(donald)
donald.df <- data.table(speech=donald, person = "Donald Trump")
sentences <- data.table(sentSplit(donald.df, "speech"))
donald <- read.table("./DonaldDebate1.txt", header = T)
donald <- read.table("./DonaldDebate1.txt", header = F)
donald <- paste(scan("./DonaldDebate1.txt", header = F), what="character", collapse = " ")
donald <- paste(scan("./DonaldDebate1.txt"), what="character", collapse = " ")
donald <- paste(scan("./DonaldDebate1.txt"), what="character", collapse = " ")
donald <- paste(scan("./DonaldDebate1.txt"), what="character", collapse = " ")
donald <- paste(scan("./DonaldDebate1.txt"), what="character", collapse = " ")
donald <- paste(scan("./DonaldDebate1.txt"), what="character", collapse = " ")
donald <- paste(scan("./DonaldDebate1.txt", what="character"), collapse = " ")
attach(donald)
wordcloud(donald)
donald.df <- data.table(speech=donald, person = "Donald Trump")
sentences <- data.table(sentSplit(donald.df, "speech"))
View(sentences)
View(sentences)
sentences[, sentence.num := seq(nrow(sentences))]
sentences[, person := NULL]
sentences[, tot := NULL]
setcolorder(sentences, c("sentence.num", "speech"))
sentences[, syllables := syllable.sum(speech)]
sentence.num <- seq(nrow(sentences))
setcolorder(sentences, c("sentence.num", "speech"))
syllables <- syllable.sum(speech)
syllable.sum(speech)
library(qdap)
syllable.sum(speech)
syllable.count(speech)
syllable_sum(speech)
syllable_sum(donald)
pol.donald <- polarity(sentences$donald)
words <- pol.donald$wc
pol <- pol.donald$polarity
pol.donald <- polarity(sentences$donald) $all
pol.donald <- polarity(sentences$speech) $all
words <- pol.donald$wc
pol <- pol.donald$polarity
plot(pol, words)
readability <- automated_readability_index(speech, sentence.num)
readability <- automated_readability_index(donald, sentence.num)
readability <- automated_readability_index(sentences, sentence.num)
readability <- automated_readability_index(donald, sentence.num)
readability <- automated_readability_index(speech, sentence.num)
readability <- automated_readability_index(sentence.num)
readability <- automated_readability_index(donald.df, sentence.num)
readability <- automated_readability_index(pol.donald, sentence.num)
readability <- automated_readability_index(words, sentence.num)
readability <- automated_readability_index(speech$sentence.num)
sentences[, readability := automated_readability_index(speech, sentence.num)
$Automated_Readability_Index]
readability <- automated_readability_index(speech, sentence.num) $Automated_Readability_Index
install.packages(c("class", "coda", "digest", "estimability", "evaluate", "foreign", "formatR", "highr", "htmltools", "knitr", "lsmeans", "MASS", "Matrix", "mgcv", "multcompView", "nlme", "nnet", "Rcpp", "rJava", "rmarkdown", "sandwich", "spatial", "stringdist"))
library(qdap)
library(data.table)
library(wordcloud)
library(ggplot2)
library(scales)
# Load data from the first Republican presidential debate from a local file.
# 'paste' loads data and concatenates it into character-based data.
# 'scan' reads list data.
donald <- paste(scan("./DonaldDebate1.txt", what="character"), collapse = " ")
attach(donald)
wordcloud(donald)
# Convert the data into a table that can later be used for more intensive analysis.
# Then, I divide the data into sentences.
donald.df <- data.table(speech=donald, person = "Donald Trump")
sentences <- data.table(sentSplit(donald.df, "speech"))
sentence.num <- seq(nrow(sentences))
setcolorder(sentences, c("sentence.num", "speech"))
syllable_sum(donald)
pol.donald <- polarity(sentences$speech) $all
words <- pol.donald$wc
pol <- pol.donald$polarity
plot(pol, words)
# Function appears to be broken, will need to find a way to fix soon.
# readability <- automated_readability_index(speech, sentence.num) $Automated_Readability_Index
readability <- automated_readability_index(speech, sentence.num) $Automated_Readability_Index
library(qdap)
library(data.table)
library(wordcloud)
library(ggplot2)
library(scales)
readability <- automated_readability_index(speech, sentence.num) $Automated_Readability_Index
summary(readability)
library(qdap)
library(data.table)
library(wordcloud)
library(ggplot2)
library(scales)
bernie <- paste(scan("./SandersDebate1.txt", what="character"), collapse = " ")
attach(bernie)
wordcloud(bernie)
donald <- paste(scan("./DonaldDebate1.txt", what="character"), collapse = " ")
attach(donald)
wordcloud(donald)
donald.df <- data.table(speech=donald, person = "Donald Trump")
sentences <- data.table(sentSplit(donald.df, "speech"))
bernie.df <- data.table(speech=bernie, person = "Bernie Sanders")
bernie.sentences <- data.table(sentSplit(bernie.df, "speech"))
check_text
sentence.num <- seq(nrow(bernie.sentences))
setcolorder(bernie.sentences, c("sentence.num", "speech"))
syllable_sum(bernie)
berniesentence.num <- seq(nrow(bernie.sentences))
setcolorder(bernie.sentences, c("sentence.num", "speech"))
syllable_sum(bernie)
berniesentence.num <- seq(nrow(bernie.sentences))
setcolorder(bernie.sentences, c("berniesentence.num", "speech"))
syllable_sum(bernie)
pol.bernie <- polarity(bernie.sentences$speech) $all
bernie.words <- pol.donald$wc
bernie.pol <- pol.bernie$polarity
plot(bernie.pol, bernie.words)
plot(pol.bernie, bernie.words)
bernie.words <- pol.bernie$wc
bernie.pol <- pol.bernie$polarity
plot(bernie.pol, bernie.words)
summary(pol.bernie)
bernie.syllables <- syllable_sum(bernie)
summary(bernie.syllables)
bernsentavg <- c(berniesentence.num/bernie.syllables)
summary(bernsentavg)
bernsentavg <- c(bernie.syllables/berniesentence.num)
summary(bernsentavg)
donald.syllables <- syllable_sum(donald)
donsentavg <- c(donald.syllables/sentence.num)
summary(donsentavg)
sentences[, readability := automated_readability_index(bernie, berniesentence.num)
$Automated_Readability_Index]
sentences[, readability := automated_readability_index(bernie, bernie.sentences)
$Automated_Readability_Index]
readability <- automated_readability_index(bernie.sentences, berniesentence.num)
readability <- automated_readability_index(pol.bernie, berniesentence.num)
bernwordavg <- c(bernie.syllables/bernie.words)
summary(bernwordavg)
bernie.wc <- word_count(bernie)
bernwordavg <- c(bernie.syllables/bernie.wc)
summary(bernwordavg)
donald.wc <- word_count(donald)
donwordavg <- c(donald.syllables/donald.wc)
summary(donwordavg)
freq_terms(bernie)
freq_term(donald)
freq_terms(donald)
citation(package = "qdap")
library(qdap)
library(data.table)
library(wordcloud)
library(ggplot2)
library(scales)
donald <- paste(scan("./DonaldDebate1.txt", what="character"), collapse = " ")
attach(donald)
wordcloud(donald)
bernie <- paste(scan("./SandersDebate1.txt", what="character"), collapse = " ")
attach(bernie)
wordcloud(bernie)
warnings()
dd6 <- paste(scan("./DonaldDebate6.txt", what="character"), collapse = " ")
attach(dd6)
wordcloud(dd6)
library(qdap)
library(data.table)
library(wordcloud)
library(ggplot2)
library(scales)
dd6 <- paste(scan("./DonaldDebate6.txt", what="character"), collapse = " ")
attach(dd6)
wordcloud(dd6)
dd6.df <- data.table(speech=dd6, person = "Donald Trump")
dd6.sent <- data.table(sentSplit(dd6.df, "speech"))
dd6.num <- seq(nrow(dd6.sent))
setcolorder(dd6.sent, c("dd6.num", "speech"))
dd6.syl <- syllable_sum(dd6)
pol.dd6 <- polarity(dd6.sent$speech) $all
dd6.words <- pol.dd6$wc
dd6.pol <- pol.dd6$polarity
dd6.wc <- word_count(dd6)
freq_terms(donald)
freq_terms(dd6)
dd6sentavg <- c(dd6.syl/dd6.num)
summary(dd6sentavg)
dd6wordavg <- c(dd6.syl/dd6.wc)
summary(dd6wordavg)
plot(pol.dd6, dd6.words)
dd5 <- paste(scan("./DonaldDebate5.txt", what="character"), collapse = " ")
attach(dd5)
wordcloud(dd5)
# Convert the data into a table that can later be used for more intensive analysis.
# Then, I divide the data into sentences.
dd5.df <- data.table(speech=dd5, person = "Donald Trump")
dd5.sent <- data.table(sentSplit(dd5.df, "speech"))
dd5.num <- seq(nrow(dd5.sent))
setcolorder(dd5.sent, c("dd5.num", "speech"))
dd5.syl <- syllable_sum(dd5)
pol.dd5 <- polarity(dd5.sent$speech) $all
dd5.words <- pol.dd5$wc
dd5.pol <- pol.dd5$polarity
dd5.wc <- word_count(dd5)
freq_terms(dd5)
dd5sentavg <- c(dd5.syl/dd5.num)
summary(dd5sentavg)
dd5wordavg <- c(dd5.syl/dd5.wc)
summary(dd5wordavg)
plot(pol.dd5, dd5.words)
jebd1 <- paste(scan(â€œ./JebDebate4.txt", what="character"), collapse = " ")
install.packages("twitteR")
install.packages("ROAuth")
twitter authentication.RData
load("twitter authentication.Rdata")
registerTwitterOAuth(cred)
library("twitteR")
library("ROAuth")
registerTwitterOAuth(cred)
?setup_twitter_oauth
setup_twitter_oauth(WAO1vs6RI6btzIoEs8YxcV7Wd, 3tWHfORS8wtnhKqVYqOqChxrspKEuXUlrayYodScGgntagjrn6, access_token=35380971-vSaBNgj9ElQPjS0CGaMcB7MAvfLStPw9ZTdwM4E7S, access_secret=4PSTLgaggOFe58IXiKoXbRqKeApv0IlTKter8G61dSU3V)
setup_twitter_oauth(WAO1vs6RI6btzIoEs8YxcV7Wd, 3tWHfORS8wtnhKqVYqOqChxrspKEuXUlrayYodScGgntagjrn6, access_token = NULL, access_secret = NULL)
setup_twitter_oauth("WAO1vs6RI6btzIoEs8YxcV7Wd", "3tWHfORS8wtnhKqVYqOqChxrspKEuXUlrayYodScGgntagjrn6", access_token = NULL, access_secret = NULL)
install("base64enc")
install.packages("base64enc")
setup_twitter_oauth("WAO1vs6RI6btzIoEs8YxcV7Wd", "3tWHfORS8wtnhKqVYqOqChxrspKEuXUlrayYodScGgntagjrn6", access_token = NULL, access_secret = NULL)
setup_twitter_oauth("WAO1vs6RI6btzIoEs8YxcV7Wd", "3tWHfORS8wtnhKqVYqOqChxrspKEuXUlrayYodScGgntagjrn6", access_token = NULL, access_secret = NULL)
setup_twitter_oauth("WAO1vs6RI6btzIoEs8YxcV7Wd", "3tWHfORS8wtnhKqVYqOqChxrspKEuXUlrayYodScGgntagjrn6", access_token = NULL, access_secret = NULL)
$clear
$ clear
clear
library(qdap)
library(data.table)
library(wordcloud)
library(ggplot2)
library(scales)
